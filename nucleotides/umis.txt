
                     integrated umis counting workflow
                     =================================
                  (using star, featurecounts and umi-tools)

this tutorial will go through an end to end analysis for single cell analysis 
using umi-tools. before you start, you will need:

*  an installed copy of umi-tools (see the installation guide)
*  [the star aligner](https://github.com/alexdobin/star)
*  a star index for the human genome
*  a transcriptome annotation. 
*  the [subread package](http://subread.sourceforge.net/), version 1.5.3 or greater.
       
this tutorial will use an example dataset generated by 10x genomics on their 
chromium platform. at the end of the tutorial we cover variations on this workflow. 
we will continue to expand this section and cover other other data types here as well. 

with 4 cores at your disposal, the whole thing should be do-able in less than an
hour for this dataset. 

the below assumes you are working in a linux environment. some changes might be 
necessary if you are working in osx, notably `wget` should be replace with `curl -o`

outline of the process:

| step                                  | inputs                         | output           |
| ------------------------------------- | ------------------------------ | ---------------- |
| find cell barcode whitelist           | read 1 fastq                   | whitelist.txt    |
| extract cb/umis and filter cbs        | r1 + r2 fastqs + whitelist.txt | extracted fastqs |
| map reads                             | extracted fastqs               | bam              |
| assign reads to genes                 | bam + transcriptome gtf        | bam              | 
| count unique reads per genes per cell | bam                            | counts.txt       |

```bash
#! /bin/env bash
# Step 1: get data
wget http://cf.10xgenomics.com/samples/cell-exp/1.3.0/hgmm_100/hgmm_100_fastqs.tar;
tar -xf hgmm_100_fastqs.tar;
cat fastqs/hgmm_100_S1_L00?_R1_001.fastq.gz > hgmm_100_R1.fastq.gz;
cat fastqs/hgmm_100_S1_L00?_R2_001.fastq.gz > hgmm_100_R2.fastq.gz;

# Step 2: Identify correct cell barcodes
umi_tools whitelist --stdin hgmm_100_R1.fastq.gz \
                    --bc-pattern=CCCCCCCCCCCCCCCCNNNNNNNNNN \
                    --set-cell-number=100 \
                    --log2stderr > whitelist.txt;
                    
# Step 3: Extract barcdoes and UMIs and add to read names
umi_tools extract --bc-pattern=CCCCCCCCCCCCCCCCNNNNNNNNNN \
                  --stdin hgmm_100_R1.fastq.gz \
                  --stdout hgmm_100_R1_extracted.fastq.gz \
                  --read2-in hgmm_100_R2.fastq.gz \
                  --read2-out=hgmm_100_R2_extracted.fastq.gz \
                  --whitelist=whitelist.txt; 

# Step 4: Map reads
STAR --runThreadN 4 \
     --genomeDir hg38_noalt_junc85_99.dir \
     --readFilesIn hgmm_100_R2_extracted.fastq.gz \
     --readFilesCommand zcat \
     --outFilterMultimapNmax 1 \
     --outSAMtype BAM SortedByCoordinate;
     
# Step 5: Assign reads to genes
featureCounts -a geneset.gtf \
              -o gene_assigned \
              -R BAM Aligned.sortedByCoord.out.bam \
              -T 4;

samtools sort Aligned.sortedByCoord.out.bam.featureCounts.bam -o assigned_sorted.bam;
samtools index assigned_sorted.bam;
              
# Step 6: Count UMIs per gene per cell
umi_tools count --per-gene --gene-tag=XT --assigned-status-tag=XS --per-cell \
                -I assigned_sorted.bam -S counts.tsv.gz
```

step 1: obtaining the data
--------------------------

the dataset was produced from around 100 cells from a mixture of human and mouse 
cells. the download is 760mb, so make sure you've got space. it can be downloaded thus:

```
$ wget http://cf.10xgenomics.com/samples/cell-exp/1.3.0/hgmm_100/hgmm_100_fastqs.tar
$ tar -x hgmm_100_fastqs.tar
```

out of the archive you will get a directory called `fastqs` that will contain 
data from 8 sequencing lanes, with three files for each lane: a read 1 file, 
a read 2 file and file containing the sample barcodes. we are not interested in 
the sample barcodes files, but for the read 1 and read2 files, we need to combine 
the eight lanes into one. by the magic of gzip, we can do with `cat`:

    $ cat fastqs/hgmm_100_S1_L00?_R1_001.fastq.gz > hgmm_100_R1.fastq.gz
    $ cat fastqs/hgmm_100_S1_L00?_R2_001.fastq.gz > hgmm_100_R2.fastq.gz

if we look at the content of of the files we will see that the first read in the 
pair contains 26nt, which correspond to a 16nt cell barcode (cb) and 10nt the 
unique molecular identifier (umi):

    $ zcat hgmm_100_R1.fastq.gz | head -n2
    @ST-K00126:308:HFLYFBBXX:1:1101:25834:1173 1:N:0:NACCACCA
    NGGGTCAGTCTAGTGTGGCGATTCAC
    +
    #AAFFJJJJJJJJJJJJJJJJJJJJJ

    -------CB-------|---UMI---
                     
we will need to remember this for the next two steps.


step 2: identifying the real cells
----------------------------------

cell barcodes are short nucleotide sequences, very much like umis, except instead 
of identifying independent molecules, they identify independent cells. we generally 
observe more of them in an experiment than there were cells. this could be for 
several reasons, including sequencing or pcr errors and the sequencing of empty 
droplets or those containing contaminants. thus we must identify which cell 
barcodes we wish to use downstream. umi-tools `whitelist` command is used to 
produce a list of cb to use downstream. 

`whitelist` currently allows the common method of taking the top x most abundant 
barcodes. x can be estimated automatically from the data using the `knee` method 
(for more detail see this <https://cgatoxford.wordpress.com/2017/05/18/
estimating-the-number-of-true-cell-barcodes-in-single-cell-rna-seq/>). 
however, it is just an estimate and for this data we've been told that there 
were 100 cells, so we can just supply that number (see variations section for 
performing the estimation for data sets where cell number is unknown).
 
     umi_tools whitelist --stdin hgmm_100_R1.fastq.gz \
                         --bc-pattern=CCCCCCCCCCCCCCCCNNNNNNNNNN \
                         --set-cell-number=100 \
                         --log2stderr > whitelist.txt

a couple of things about this command: 

### input files

    firstly, note that fastq file that contains the barcodes is passed to
    `--stdin`, this tells `whitelist` to read the data from this file rather than 
    from stdin. this of coursemeans you could pass data using standard pipes. 

### plots

    the `--plot-prefix` option tells `whitelist` to output summary plots for the 
    frequency of each cb. we always recommend running with this option in order 
    to visualise whether the number of cells accepted seems reasonable. see 
    [variations](automatic estimation of cell number) for a more complete 
    explanation of what these plots show.

### specifying barcode locations

    second, the `--bc-pattern`. this tells `whitelist` where to find the cb and 
    umi in the read sequence. by default we assume the barcodes are at the 5' 
    end of the read (this can be changed with `--3prime`). we then use `c` 
    characters to show where cb bases are and `n` characters to show were umi 
    bases are. thus, in the above we have 16 `c`s followed by 10 `n`s to denote 
    that the first 16 bases of the read are cb bases and the second 16 are umi 
    bases. alternatively, you can also define the barcode pattern using a regex 
    instead (--extract-method=regex) in which there are named groups to define 
    the positions for the cell barcode and umi. for example we would change the 
    above command to:
    
    umi_tools whitelist --stdin hgmm_100_R1.fastq.gz \
                        --bc-pattern='(?P<cell_1>.{16})(?P<umi_1>.{10})' \
                        --extract-method=regex \
                        --set-cell-number=100 \
                        --log2stderr > whitelist.txt
                        
    this interface is very powerful and flexible and allows for the specification of 
    all sorts of interesting things, like variable length cbs (umis do have to be a 
    fixed length) and tolerant linker sequences (see the indrop example in 
    [variations](#barcode-extraction-for-indrop) and `umi_tools whitelist --help`).

### specifying outputs

    by default umi-tools outputs everything, final output, logging info and 
    progress report, to the standard out pipe. downstream sections will take this 
    output just fine, but you might want to put the log somewhere else, like a 
    separate file, or on the terminal. this can be achieved in one of several ways:
    
    * you could redirect the final output using the `--stdout` or `-s` options. 
      the final output will be directed to a file and the log will continue to 
      come on stdout.

    * you could redirect the log to a file with `--stdlog` or `-l`. the log and 
      progress will be saved to a file and the final output sent to the standard out.

    * you can redirect the log and progress to the standard err using 
      `--log2stderr` as above. 
      
    * you can switch off the log/progress with `-v 0`
    
    this applies to all the umi-tools commands. 

### using umi counts rather than read counts in umi_tools whitelist

    many published protocols rank cbs by the number of reads the cbs appear in. 
    however you could also use the number of unique umis a cb is associated with. 
    note that this is still an approximation to the number of transcripts captured 
    because the same umi could be associated with two different transcripts and 
    be counted as independent. activate this with `--method=umis`.

### contents of `whitelist.txt`

    the output of the whitelist command is a table containing the accepted cbs. 
    it has four columns: 

    1. the accepted cb
    2. comma separated list of other cbs within an edit distance of the cb in 
       columns 1 and >1 edit away from any other accepted cb.
    3. the abundance (read or umi count) of the accepted.
    4. comma separated list of abundances for the cbs in column 2

    e.g:
    
    ```
    $ head whitelist.txt 
    AAAGATGAGAAACGAG	AAAAATGAGAAACGAG,AAACATGAGAAACGAG,...	53122	4,6,...
    AAAGCAAGTACCTACA	AAAACAAGTACCTACA,AAACCAAGTACCTACA,...	36255	2,3,...
    AACACGTCAGCGTAAG	AAAACGTCAGCGTAAG,AACAAGTCAGCGTAAG,...	53133	4,11,...
    ```
    (i have truncated columns 2 and 4 for easy viewing)
    as we asked for 100 cells, this file should contain 100 lines:
    
    ```
    $ wc -l whitelist.txt 
    100 whitelist.txt
    ```


step 3: extract the barcodes and filter the reads
-------------------------------------------------

the next step is to extract the cb and umi from read 1 and add it to the read 2 
read name. we will also filter out reads that do not match one of the accepted cell barcode. 
the most basic form of this is executed with:

```
umi_tools extract --bc-pattern CCCCCCCCCCCCCCCCNNNNNNNNNN \
                  --stdin hgmm_100_R1.fastq.gz \
                  --stdout hgmm_100_R1_extracted.fastq.gz \
                  --read2-in hgmm_100_R2.fastq.gz \
                  --read2-out hgmm_100_R2_extracted.fastq.gz \
                  --whitelist whitelist.txt 
```

the `--bc-pattern` and `--stdin` options are as before. note that we send the 
standard out (which contains the extract read 1s) to the a file (add `.gz` to 
the end of the name will trigger automatic compression). `--read2-in` and 
`--read2-out` specify the output files for read 2. finally `--whitelist` passes 
the list of accepted cbs generated in the previous step and tells `extract` to 
only output those reads that contain accepted cbs. 

as the end of the log makes clear, the command above took about 20 minutes

```
2017-08-10 16:29:45,449 INFO Parsed 7100000 reads
2017-08-10 16:30:01,896 INFO Input Reads: 7197662
2017-08-10 16:30:01,896 INFO Reads output: 5963891
2017-08-10 16:30:01,896 INFO Filtered cell barcode: 1233771
# job finished in 1175 seconds
```

there should now be two output files in your directory: `hgmm_100_r1_extracted.fastq.gz` 
and `hgmm_100_r2_extracted.fastq.gz`. looking at the first read we see:

```
$ zcat hgmm_100_R1_extracted.fastq.gz | head -n4
@ST-K00126:308:HFLYFBBXX:1:1101:31345:1261_AACTCTTGTTCTGAAC_CGGTTGGGAT 1:N:0:NACCACCA

+
```

the reads are now empty because the cbs and umis have now been moved from the 
read sequence to the read name, and there is nothing left. we will not need 
this file again.

if we look at the read 2:

```
$ zcat hgmm_100_R2_extracted.fastq.gz | head -n4
@ST-K00126:308:HFLYFBBXX:1:1101:31345:1261_AACTCTTGTTCTGAAC_CGGTTGGGAT 2:N:0:NACCACCA
CCTTTTTGGAACCAACAATAGCAGCTCCATTTCTGGAGTCTGGGTCTTCCGAGGCCAGGAGCTCGCCTTTCCGCCGAGCCCAGATTGGCAGGTGGACT
+
A<<AFAFFFJJJJFJJJFA<7<FJF-AAJF7-FFF<FA7AFFFJ-77<JJFFFJJJJFAJFJ7-7AJ-7-FJJJ--)7-77F-F--AAAJAA-7-7F7
```

we can see that the cb and umi from read 1 has been added to the name of read 2 
as well. these reads are now ready to map!

### Discarding read 1

    There are many single cell RNA-Seq techniques where read 1 only contains 
    barcodes, as above. If we only want to write out the extracted read 2 file 
    we can supply the `--read2-stdout` option to output read 2 on the stdout 
    and discard read 1.


step 4: mapping reads
---------------------

at this point there are two different ways we might proceed. we could map to the 
transcriptome, where each each contig represents a different transcript. 
alternatively we could map to the genome and then assign reads to genes. while 
transcriptome mapping allows for easier downstream analysis, we recommend mapping 
to the genome because it doesn't force reads to map to transcripts when a better 
match outside an annotated gene exists. however, there are cases when transcriptome 
mapping should be favoured, and we discuss this in the 
[variations](#mapping-to-the-transcriptome-rather-than-genome) section. 

we are going to use star here as our mapper, but you can substitute whichever 
splice-aware aligner you prefer. we are mapping to an index built on the human 
ncbi38 reference, with the alternate contigs removed (referred to by ncbi as the 
"analysis read set") using junctions from ensembl85 and a 99nt overhang. 
we do not allow multimapping reads. 

```bash
$ STAR --runThreadN 4 \
       --genomeDir hg38_noalt_junc85_99.dir \
       --readFilesIn hgmm_100_R2_extracted.fastq.gz \
       --readFilesCommand zcat \
       --outFilterMultimapNmax 1 \
       --outSAMtype BAM SortedByCoordinate
```

if we have a look at the stats for this, we will see that 63.02% of reads mapped 
(depending on exactly how you've built your star index you may get a slightly 
different number). for 8.1% of these this is because of mapping to more than one 
location. the rest is probably because the sample contains both mouse and human 
cells, but we are only aligning to the human genome. in fact, given that, the 
mapping rate looks a bit on the high side: we are probably mapping some reads to 
the human genome that actually came from the mouse genome. ideally we would 
perform this mapping using references that combined both the mouse and human 
genomes/transcriptomes. on our systems, using 4 threads, this mapping takes 
about 7 minutes. 


step 5: assigning reads to genes
--------------------------------

many of the single cell techniques that use umis are 3' tag count methods. this 
is important because it means that the umis are generally added before pcr and 
then fragmentation. this means that two reads from the same gene might have 
different mapping locations and still represent duplicates, as long as they come 
from the same gene. therefore, umi-tools need to know which gene each read came 
from. when reads are aligned to the transcriptome, this is easy as it is given 
by the contig (and possibly a gene to transcript look up table). however, with a 
genome alignment we need to assign reads to genes. 

we can do this with the `featurecounts` tool from the `subread` package. as well 
as outputting a table of (undeduplicated) counts, we can also instruct 
`featurecounts` to output a bam with a new tag containing the identity of any 
gene the read maps to. 

**warning**: this only works on featurecounts from subread 1.5.3 and above, 
which was released july 2017. if you already have subread it could well need updating

you will need a geneset to assign genes to. here ours is called `geneset.gtf`. 
it is the same geneset used to generate the mapping index above, and is based on 
the gencode annotations. 

    $ featureCounts -a geneset.gtf -o gene_assigned -R BAM Aligned.sortedByCoord.out.bam -T 4

unfortunately the bam output by featurecounts is no longer sorted, 
so we now need to sort the bam.

    $ samtools sort Aligned.sortedByCoord.out.bam.featureCounts.bam -o assigned_sorted.bam
    $ samtools index assigned_sorted.bam

we now have a sorted, indexed set of alignments assigned to the appropriate 
genes and we can now count the number of distinct umis mapping to each gene in each cell.


step 6: counting molecules
--------------------------

we are finally ready to process the umis aligned to each gene in each cell to 
find the number of distinct, error corrected umis mapping to each gene. 

```bash
$ umi_tools count --per-gene --gene-tag=XT \
                  --assigned-status-tag=XS --per-cell \
                  -I assigned_sorted.bam -S counts.tsv.gz
```

since we want to count the number of umis per gene, and the gene assignment is 
encoded in the xt tag, we use the `--per-gene --gene-tag=xt` options. 
featurecounts also uses the xs tag to describe the gene assignment so we use the 
`--assigned-status-tag=xs` option. any reads with an assignment matching 
`^[__|unassigned]` (default value for `--skip-tags-regex`) will be skipped. 
`--per-cell` tells umi-tools to also consider the cb and produce a separate count 
for each cell. the counts are output in a table with three columns: the gene_id, 
the cell barcode and the count of deduplicated umis. running this command on 
this input takes 72 seconds on our system. 

```
$ zcat counts.tsv.gz | head
gene	cell	count
ENSG00000000003	AAAGATGAGAAACGAG	3
ENSG00000000003	AACTCTTGTTCTGAAC	4
ENSG00000000003	ACACCGGGTACGACCC	2
ENSG00000000003	ACACTGAGTCGGGTCT	5
ENSG00000000003	ACTATCTCAAGGTGTG	2
ENSG00000000003	ACTGTCCCATATGGTC	11
ENSG00000000003	ACTGTCCTCATGCTCC	5
ENSG00000000003	AGAGCTTCACGACGAA	2
ENSG00000000003	AGCGGTCTCGATAGAA	2
```

if you'd rather have this as a matrix, which each cell as a sepearte column, you 
can specify `--wide-format-cell-counts`. you can also output deduplicated reads 
using the `dedup` command in place of `count`. you can even output all reads, 
with each assigned to an umi group, using the `group` command, although see below 
for some important points.


variations
----------

### regex barcode specification

    the cbs for [indrop](1) are different lengths. thus, we must use 
    `--extract-method=regex` since we can no longer encode the barcode pattern 
    in a simple string. if we look at the sequence of an indrop read 1, we can 
    demark the barcodes as follows:
    
        TGAACATCTATGAGTGATTGCTTGTGACGCCTTGAGCCCATCCTGCTTTTTTTTT
        ---CB-1---|------ADAPTER--------|--CB-2-|-UMI-|poly(T)

    the cb is split into two halves. cb-1 can be 8-12bp, the adapter sequence 
    is always "gagtgattgcttgtgacgcctt", cb-2 is 8bp, umi is 6bp and the read ends 
    in a poly(t) seqeunce. in the case above, the barcode sequences are:
    
        CB-1: TGAACATCTAT
        CB-2: GAGCCCAT
        CB (CB-1 + CB-2): TGAACATCTATGAGCCCAT
        UMI: CCTGCT
    
    to encode this in the barcode pattern, we must provide the option 
    `--extract-method=regex` and provide `--bc-pattern` with a regex with groups 
    named accordingly. each group must have a integer suffix:
    
        --bc-pattern "(?P<cell_1>.{8,12})(?P<discard_1>GAGTGATTGCTTGTGACGCCTT)(?P<cell_2>.{8})(?P<umi_1>.{6})T{3}.*"`
    
    this translates to: 8-12 characters (group="cell_1"), followed by 
    "gagtgattgcttgtgacgcctt" (group="discard_1"), followed by 8 characters 
    (group="cell_2"), followed by 6 characters (group="umi_1"), followed by 
    3 or more "t"s.
    
    the other benefit of using a regex is that we can perform 'fuzzy'
    <https://pypi.python.org/pypi/regex/>. for example, the indrop adapter 
    sequence is 22bp long so it may sometimes contain base calling errors. 
    we can allow usp to two substituions like so:
    
        --bc-pattern "(?P<cell_1>.{8,12})(?P<discard_1>GAGTGATTGCTTGTGACGCCTT){s<=2}(?P<cell_2>.{8})(?P<umi_1>.{6})T{3}.*"`
    
    it should be possible to encode any conceivable pattern of barcodes using a regex.

### automatic estimation of cell number

    in [step 2](#step-2:-identifying-the-real-cells) above, we generated a 
    whitelist of accepted ("true") cbs and provided the option `--set-cell-number=100` 
    since we a prior belief about the number of cells we had sequenced. however, 
    what if we didn't know how many cells we had actually sequenced? well, in 
    that case, we can leave out the `--set-cell-number` option and let `whitelist` 
    estimate the number of true cbs automatically. even better, if we have an 
    estimate on the number of cells we have input into the system and we know 
    the capture rate is at least 10% (this assumption holds true for indrop and
    10x chromium platforms), we can provide the estimated number of input cells 
    as an upper limit on the number of true cbs using the `--expect-cells` 
    option. so, imagine with our experiment above, we estimated that around 200 
    cells were input into the system, we can generate the whitelist with the 
    following command:

        umi_tools whitelist --stdin hgmm_100_R1.fastq.gz \
                            --bc-pattern=CCCCCCCCCCCCCCCCNNNNNNNNNN \
                            --expect-cells=200 \
                            --plot-prefix=expect_whitelist \
                            --log2stderr > whitelist.txt

    we can check how many cbs we accepted:

        $ wc -l whitelist.txt 
        119 whitelist.txt

    based on our prior knowledge that there were ~100 true cbs, we've probably 
    slightly over-estimated the number of cbs here. we can visualise this by 
    looking at the following plots which present the same data in different ways 
    to help assess the threshold.

    for all plots, the 'selected' local minima (or threshold) is shown by the 
    dashed line. if we had other local minima which were 'rejected' these would 
    also be shown. the thresholds are also tabulated in the file 
    `expect_whitelist_cell_thresholds.tsv`. in figure 1, we can see two clear 
    peaks, with the right peak representing the true cell barcodes. in this case, 
    the selected local minima appears to be in the correct place. this is
    confirmed in figures 2 & 3, where the threshold appears to be at the 'knee' 
    in the cumulative counts, and counts per barcode. so it looks like in this 
    case, the automatic detection of the 'knee' has worked well. however, in some 
    cases, the automatic selection may not work so well. in these case we can 
    re-run `whitelist` and set the number of cells with the `--set-cell-number` 
    option as described above. 

    in most cases, there will be many local minima and sometimes the wrong one 
    may be selected. if so, you can insepect the `**_cell_thresholds.tsv` 
    file and re-run the `whitelist` command using the `--set-cell-number` option 
    with the threshold which you have deemed to be most appropriate. we've not 
    yet come across a case where no local minima identified near the 'knee', 
    but if so, you can inspect the counts per barcode and cumulative counts 
    figures and estimate a number to use with the `--set-cell-number` option.

### quality filtering and masking barcodes
    
    in some cases, the umi bases may have very low base call quality scores. 
    there are three options to deal with these reads:

    1. retain
    2. discard
    3. mask

    by defualt, `extract` takes option 1 and does not considered quality scores. 
    if you want to take option 2 and discard these reads you can do so with 
    `--quality-filter-threshold`, whereby all reads where the umi contains a 
    base with a phred scrore below `filter` are discarded. however, if you are 
    concerned about low quality bases, our recommendation is that you take option 
    3 and use `--quality-filter-mask=[filter]` to replace all umi bases with a 
    phred score below `filter` with an "n". umis with an "n" will be 1-edit 
    distance away from their cognate error-free umi sequence and will therefore 
    be handled sensibly by the downstream umi-tools commands.

### mapping to the transcriptome rather than genome

    many single cell protocols recommend mapping to the transcriptome rather 
    than the genome. this makes downstream processing easier. in paritcular it 
    makes it easier to know when you've seen all the reads from a gene, so 
    deduplication can happen. this leads to a reduced memory footprint, which is 
    particularly obvious in `dedup` and `group`. however, there are problems. 
    
    1. when you map to the transcriptome almost all reads are multimapping as 
       most sequence in a gene is part of more than one transcript. this makes it 
       difficult to distinguish between genuninely multimapping reads and reads 
       that just come from multiple transcripts of the same gene.

    2. if we include these reads we also face the problem that reads will be 
       double counted, and each time the deduplication is done, it will be done 
       using a different set of other reads, thus a read might filtered as a 
       duplicate for one transcript but not another.

    3. reads that should map elsewhere might be forced to map to the transcriptome. 
    
    it turns out we can solve either problems 1 + 2 or problem 3. this is why we 
    recommend mapping to the genome and annotating with `featurecounts` above.
    
    we solve problems 1 and 2 by using a collapsed transcriptome where all 
    transcripts for a gene are merged into a single model. this is similar to 
    the supertranscript concept proposed by davidison et al
    <https://genomebiology.biomedcentral.com/articles/10.1186/s13059-017-1284-1>. 
    you can download our merged transcriptome annotations for human gencode 26 
    and mouse gencode 15, or see below for instructions on generating your own. 
    you should generate fasta from these, and then genome indexes for your 
    favorite spliced aligner. after alignment the contigs of the aligned bam 
    file will contain the gene_id. you can then run `count`, `dedup` or `group` with:
    
        $ umi_tools [COMMAND] --per-contig -I aligned.bam
    
    you'll find that after the effort of generating the genome and its indexes, 
    the `umi_tools` step is quicker and uses less memory, and the `featurecounts` 
    step is unecessary. 
    
    the above doesn't solve the third problem above however. we can get 
    transcriptome aligned reads without the problem three using `star`. star has 
    an output mode `--quantmode transcriptomesam` where reads are mapped to the 
    genome, but then their mapping coordinates are translated to the transcriptome 
    and output in that form. for this you would pass `star` a normal transcriptome 
    (i.e. not one of the collasped ones from above) using `--sjdbgtffile` option. 
    you could then sort the `bam` file and run `umi_tools` with:
    
        $ umi_tools [COMMAND] --per-contig --per-gene --gene-transcript-map=[MAPFILE]
    
    where `mapfile` is a tab-sepearted text file mapping transcript_ids 
    (in column 1) to gene_ids (in column 2). however, since we might encounter 
    the same read twice (mapped to different transcripts of the same gene), umi 
    counts might be inaccurate.
    
    ideally we'd like to combine these two methods: map to the genome and then 
    have star translate to merged transcriptome coordinates. unfortunately `star` 
    will only transfer reads that fit the intron/exon structure of the collapsed 
    gene, which looses many splice junctions, and therefore about 10% of reads are lost.
    
### Generating merge transcriptome annotations
    
    We generated the above linked collapsed transcriptomes using the 
    [`cgat` pacakge](https://github.com/CGATOxford/cgat) and files from gencode. 
    This involves repeated use of the `gtf2gtf` tool, which first merges the 
    transcripts, and then sets the `transcript_id` of every exon to be equal 
    to the `gene_id`.
    
    For example, for the human transcriptome:
    
    $ wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_26/gencode.v26.annotation.gtf.gz
    $ cgat gtf2gtf --method=merge-exons -I gencode.v26.annotation.gtf.gz \
      | cgat gtf2gtf --method=set-transcript-to-gene -S hg38_genocode26_merged.gtf.gz
